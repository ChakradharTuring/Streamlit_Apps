{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c879125",
   "metadata": {},
   "source": [
    "# Import data from google big query for new devs and store in local"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4242225",
   "metadata": {},
   "source": [
    "## Imports and global declarations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70f7f096",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 freeze > \"../requirements.txt\"\n",
    "#!pip3 install -r \"../requirements.txt\"  # giving some error\n",
    "\n",
    "from google.cloud import bigquery\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas_gbq\n",
    "import copy\n",
    "import copy\n",
    "import pickle\n",
    "import datetime as dt\n",
    "from datetime import timezone\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e6c8ed",
   "metadata": {},
   "source": [
    "## Custom function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df4875eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GBQ_data(query_string):\n",
    "    client = bigquery.Client('turing-230020')\n",
    "    query = client.query(query_string)\n",
    "    results = query.result()\n",
    "    return results.to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57929a1b",
   "metadata": {},
   "source": [
    "## Getting dev ids of new developers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67a46709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(136, 45)\n"
     ]
    }
   ],
   "source": [
    "df_phase2_query = \"\"\"SELECT * FROM analytics_views.phase2_step1_dev_aggregated\n",
    "LEFT JOIN analytics_views.phase2_step2_dev_packet_aggre using(dev_id)\n",
    "LEFT JOIN analytics_views.phase2_step3_dev_interview_aggre using(dev_id)\n",
    "LEFT JOIN analytics_views.phase2_step4_dev_trials_and_engagements using (dev_id) where # phase2_entry_date >= '2022-07-19' and\n",
    "dev_id not in (Select dev_id from turing-dev-337819.pdsa.PDAS_P2_cluster)\"\"\"\n",
    "\n",
    "df_phase2 = GBQ_data(df_phase2_query)\n",
    "df_phase2['count_paying_cust'] = df_phase2['count_paying_cust'].fillna(0)\n",
    "df_phase2['paying_cust'] = np.where(df_phase2['count_paying_cust'] > 0, 1 , 0)\n",
    "print(df_phase2.shape)\n",
    "df_phase2.head()\n",
    "dev_ids = list(df_phase2['dev_id'].values)\n",
    "devs = str(dev_ids).strip('[]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44b8e77",
   "metadata": {},
   "source": [
    "## Download raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df48f5b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " developer_detail Data shape is (136, 56) and unique developers are 136\n",
      " phase1_data Data shape is (136, 66) and unique developers are 136\n",
      " dev_availability Data shape is (135, 5) and unique developers are 135\n",
      " df_phase2 Data shape is (136, 45) and unique developers are 136\n",
      " nts Data shape is (11, 2) and unique developers are 11\n",
      " acc_lci Data shape is (116, 4) and unique developers are 116\n",
      " self_dec_skills Data shape is (136, 4) and unique developers are 136\n",
      " sns Data shape is (135, 2) and unique developers are 135\n",
      " ml_mcq Data shape is (134, 11) and unique developers are 134\n",
      " Global Data shape is (136, 54) and unique developers are 136\n",
      " Global Data shape is (136, 59) and unique developers are 136\n"
     ]
    }
   ],
   "source": [
    "developer_detail_query = \"\"\"SELECT country.country_group, dd.*, length(dd.resume_plain) characters_in_reume \n",
    "from  devdb_mirror.developer_detail dd left join \n",
    "analytics_views.country_information country on dd.country_id=country.country_id\n",
    "where user_id in %s\"\"\" %(\"(\" + devs + \")\") \n",
    "developer_detail = GBQ_data(developer_detail_query)\n",
    "developer_detail.rename(columns = {'user_id':'dev_id'}, inplace=True)\n",
    "developer_detail['region'] = np.where(developer_detail['country_group']==\"Latin and South America\", 'LATAM', 'RoW')\n",
    "print(f\" developer_detail Data shape is {developer_detail.shape} and unique developers are {developer_detail['dev_id'].nunique()}\")\n",
    "\n",
    "phase1_data_query = \"\"\" SELECT * from `turing-230020.analytics_views.phase1_dev_level_data` \n",
    "where dev_id in %s\"\"\" %(\"(\" + devs + \")\")\n",
    "phase1_data = GBQ_data(phase1_data_query)\n",
    "print(f\" phase1_data Data shape is {phase1_data.shape} and unique developers are {phase1_data['dev_id'].nunique()}\")\n",
    "\n",
    "dev_availability_query = \"\"\" SELECT user_id as dev_id, answer as latest_availability ,  action_from as updated_by,\n",
    "last_update as last_update_availability, notice_period\n",
    "from `turing-230020.devdb_mirror.dv2_developer_availability`\n",
    "where user_id in %s\"\"\" %(\"(\" + devs + \")\")\n",
    "dev_availability = GBQ_data(dev_availability_query)\n",
    "print(f\" dev_availability Data shape is {dev_availability.shape} and unique developers are {dev_availability['dev_id'].nunique()}\")\n",
    "\n",
    "df_phase2_query = \"\"\"SELECT * FROM analytics_views.phase2_step1_dev_aggregated\n",
    "LEFT JOIN analytics_views.phase2_step2_dev_packet_aggre using(dev_id)\n",
    "LEFT JOIN analytics_views.phase2_step3_dev_interview_aggre using(dev_id)\n",
    "LEFT JOIN analytics_views.phase2_step4_dev_trials_and_engagements using (dev_id) where dev_id in %s\"\"\" %(\"(\" + devs + \")\")\n",
    "df_phase2 = GBQ_data(df_phase2_query)\n",
    "df_phase2['count_paying_cust'] = df_phase2['count_paying_cust'].fillna(0)\n",
    "df_phase2['paying_cust'] = np.where(df_phase2['count_paying_cust'] > 0, 1 , 0)\n",
    "print(f\" df_phase2 Data shape is {df_phase2.shape} and unique developers are {df_phase2['dev_id'].nunique()}\")\n",
    "\n",
    "nts_query = \"\"\"\n",
    "SELECT distinct developer_id as dev_id, 1 as NTE_status  FROM `turing-230020.devdb_mirror.ms2_negotiations`\n",
    "where developer_id in %s\"\"\" %(\"(\" + devs + \")\")\n",
    "nts = GBQ_data(nts_query)\n",
    "print(f\" nts Data shape is {nts.shape} and unique developers are {nts['dev_id'].nunique()}\")\n",
    "\n",
    "acc_lci_query = \"\"\"\n",
    "with lci as(\n",
    "SELECT user_id as lci_user_id, count(*) lci_attempts, max(total_score_by_cases) lci_score \n",
    "FROM `turing-230020.devdb_mirror.dv2_challenge_submit` \n",
    "where challenge_id=201 and user_id in %s\n",
    "group by 1),\n",
    "\n",
    "acc as(\n",
    "SELECT user_id as acc_user_id, count(*) acc_attempts, max(total_score_by_cases) acc_score\n",
    "FROM  `turing-230020.devdb_mirror.dv2_challenge_submit` AS dcs\n",
    "WHERE  challenge_id = 220 and user_id in %s\n",
    "GROUP by 1\n",
    "),\n",
    "\n",
    "acc_lci as(\n",
    "SELECT lci_user_id, acc_user_id,  COALESCE(lci_user_id, acc_user_id) user_id,\n",
    "acc_score, lci_score, COALESCE(acc_score, lci_score) as score\n",
    "from lci full outer join acc on lci.lci_user_id=acc.acc_user_id\n",
    ")\n",
    "\n",
    "SELECT user_id as dev_id, acc_score, lci_score, \n",
    "COALESCE(acc_score, lci_score) as acc_lci_score \n",
    "from acc_lci;\n",
    "\"\"\" %(\"(\" + devs + \")\", \"(\" + devs + \")\")\n",
    "\n",
    "acc_lci = GBQ_data(acc_lci_query)\n",
    "print(f\" acc_lci Data shape is {acc_lci.shape} and unique developers are {acc_lci['dev_id'].nunique()}\")\n",
    "\n",
    "self_dec_skills_query = \"\"\"\n",
    "SELECT developer_id as dev_id, count(distinct skill_id) num_skill, \n",
    "string_agg(distinct cast(skill_id as string), ',' ) as dev_skill_id,\n",
    "string_agg(distinct skill_name, ',' ) as dev_skill_name\n",
    "from(\n",
    "SELECT dev.*, skill.skill_name from `turing-230020.devdb_mirror.tpm_developer_skill` dev\n",
    "left join `turing-230020.devdb_mirror.base_all_skills_v4` skill on dev.skill_id = skill.id\n",
    "where developer_id in %s\n",
    ")\n",
    "GROUP by 1\"\"\" %(\"(\" + devs + \")\") \n",
    "self_dec_skills = GBQ_data(self_dec_skills_query)\n",
    "print(f\" self_dec_skills Data shape is {self_dec_skills.shape} and unique developers are {self_dec_skills['dev_id'].nunique()}\")\n",
    "\n",
    "sns_qeury = \"\"\"\n",
    "SELECT\n",
    "  dcs.user_id AS dev_id,\n",
    "  AVG(dweas.avg_score) AS sn_avg_score\n",
    "FROM\n",
    "  devdb_mirror.dv2_challenge_submit AS dcs\n",
    "  LEFT JOIN devdb_mirror.dv2_work_experience_avg_score AS dweas ON dcs.submit_id = dweas.submit_id\n",
    "  where user_id in %s\n",
    "GROUP BY\n",
    "  dcs.user_id\"\"\" %(\"(\" + devs + \")\")\n",
    "sns = GBQ_data(sns_qeury)\n",
    "sns.rename(columns = {'sn_avg_score':'seniority_score'}, inplace=True)\n",
    "print(f\" sns Data shape is {sns.shape} and unique developers are {sns['dev_id'].nunique()}\")\n",
    "\n",
    "stack_mcq_mapping_query = \"\"\"with stack as(\n",
    "SELECT stack_demand_id as stack_id, stack_demand_name as stack_name, \n",
    "count(distinct mcq_id) as num_mcq, \n",
    "count(distinct skill_id) as num_skill,\n",
    "string_agg(distinct cast(mcq_id as string), ',') as mcq_id, \n",
    "string_agg(distinct cast(skill_id as string), ',') as skill_id\n",
    "from `turing-230020.devdb_mirror.dv2_stack_demand_skills` \n",
    "left join `turing-230020.devdb_mirror.dv2_skill_mcq` using(skill_id) \n",
    "left join `turing-230020.devdb_mirror.dv2_stack_demand` using(stack_demand_id)\n",
    "where require=1 and mcq_id not in (107,140,142,237) -- and require_for_job=1 \n",
    "group by 1,2)\n",
    "\n",
    "SELECT * except(rn) from (SELECT *, row_number() over (partition by mcq_id order by stack_name desc) as rn\n",
    "from stack ) where rn=1 \n",
    "\"\"\"\n",
    "\n",
    "skill_mcq_mapping_query = \"\"\"with skill_mcq_mapping as(\n",
    "SELECT skill_name as skill_challenge_name, skill_id, mcq_id from(\n",
    "SELECT * , row_number() over (partition by mcq_id order by length(skill_name), skill_id) as rn from(\n",
    "SELECT skill_mcq.skill_id, base_skill.skill_name, \n",
    "string_agg(cast(skill_mcq.mcq_id as string), ',') mcq_id , \n",
    "from `turing-230020.devdb_mirror.dv2_skill_mcq` skill_mcq \n",
    "left join `turing-230020.devdb_mirror.base_all_skills_v4` base_skill on skill_mcq.skill_id=base_skill.id\n",
    "where skill_id in(\n",
    "select skill_id from `turing-230020.devdb_mirror.dv2_skill_mcq` GROUP by 1 having count(*)>1\n",
    ") GROUP by 1,2)) where rn=1\n",
    "\n",
    "UNION all\n",
    "\n",
    "SELECT challenge_name as skill_challenge_name,skill_id, mcq_id from(\n",
    "SELECT * , row_number() over (partition by mcq_id order by skill_id) as rn from(\n",
    "SELECT skill_mcq.skill_id, ch_name.challenge_name, \n",
    "string_agg(cast(skill_mcq.mcq_id as string), ',') mcq_id , \n",
    "from `turing-230020.devdb_mirror.dv2_skill_mcq` skill_mcq \n",
    "left join `turing-230020.devdb_mirror.base_all_skills_v4` base_skill on skill_mcq.skill_id=base_skill.id\n",
    "left join `turing-230020.devdb_mirror.dv2_challenge` ch_name on skill_mcq.mcq_id=ch_name.challenge_id\n",
    "where skill_id in(\n",
    "select skill_id from `turing-230020.devdb_mirror.dv2_skill_mcq` GROUP by 1 having count(*)<2\n",
    ") GROUP by 1,2)) where rn=1\n",
    ")\n",
    "\n",
    "SELECT * from skill_mcq_mapping\n",
    "\"\"\"\n",
    "\n",
    "skill = GBQ_data(skill_mcq_mapping_query)\n",
    "stack = GBQ_data(stack_mcq_mapping_query)\n",
    "\n",
    "skill['skill_challenge_name'] = skill['skill_challenge_name'].str.replace(' ','')\n",
    "skill.loc[skill['skill_challenge_name']=='Python', 'mcq_id'] = '211'  # 107 is deprecated and catered in ml_mcq\n",
    "skill.loc[skill['skill_challenge_name']=='Vue.js', 'mcq_id'] = '208'  # 140 is deprecated and catered in ml_mcq\n",
    "skill.loc[skill['skill_challenge_name']=='DevOps', 'mcq_id'] = '236'  # 142 has same name DevOps\n",
    "skill.loc[skill['skill_challenge_name']=='AmazonRedshift', 'mcq_id'] = '164,240' # 237 has same name \n",
    "\n",
    "skill['mcq_id_set'] = skill['mcq_id'].apply(lambda x : x.split(',',-1)).apply(lambda x : set(map(int,x)))\n",
    "stack['mcq_id_set'] = stack['mcq_id'].apply(lambda x : x.split(',',-1)).apply(lambda x : set(map(int,x)))\n",
    "\n",
    "#ml_mcq = pd.read_csv(path_of_ML_MCQ)\n",
    "#ml_mcq = ml_mcq[ml_mcq['dev_id'].isin(dev_ids)]\n",
    "ml_mcq_query = \"\"\"with per as(\n",
    "select\n",
    "dms.dev_id, dms.challenge_name, dms.challenge_id, dms.problems_in_challenge, dms.num_attempted, dms.num_correct,\n",
    "dms.probability_correct, dms.dev_rank, dms.dev_percentile, dms.dev_weight, dms.last_updated_at, dms.from_model, \n",
    "dsm.skill_id, dsm.mcq_id, bas4.skill_name, dms.skill_id as dms_skill_id\n",
    "  from \n",
    "    external_query(\"turing-230020.us.machine-learning\",\n",
    "      \"select * from prod.dev_mcq_score\"\n",
    "    ) as dms\n",
    "  left join devdb_mirror.dv2_skill_mcq as dsm\n",
    "    on dms.challenge_id = dsm.mcq_id\n",
    "  left join devdb_mirror.base_all_skills_v4 as bas4\n",
    "    on dsm.skill_id = bas4.id where dev_id in %s\n",
    "    ),\n",
    "\n",
    "per_2 as(\n",
    "SELECT * except(challenge_id), \n",
    "case when challenge_id=142 then 236 when challenge_id=237 then 240 else challenge_id end as challenge_id\n",
    "from per), \n",
    "\n",
    "dev_mcq as (\n",
    "SELECT * except(rn) from (SELECT *, row_number() over (partition by dev_id, challenge_id order by dev_percentile desc, last_updated_at) as rn\n",
    "from per_2 ) where rn=1 \n",
    ")\n",
    "\n",
    "SELECT dev_id, \n",
    "count(distinct challenge_id) as num_challenges,\n",
    "string_agg(cast(challenge_id as string), ',') as challenge_ids,\n",
    "count(case when dev_percentile > 50 then challenge_id else null END) as passed_num_challenges ,\n",
    "string_agg(CASE WHEN dev_percentile > 50 then cast(challenge_id as string) else null END, ',') AS passed_challenge_ids,\n",
    "string_agg(CASE WHEN dev_percentile > 50 then challenge_name else null END, ',') AS passed_challenge_name,\n",
    "SUM(problems_in_challenge) as total_problems,\n",
    "sum(num_attempted) as attempted_problems,\n",
    "sum(num_correct) as num_correct,\n",
    "string_agg(cast(dev_percentile as string), ',') as dev_percentile,\n",
    "avg(dev_percentile) as mean_dev_percentile\n",
    "from dev_mcq WHERE challenge_id in (SELECT distinct mcq_id from `turing-230020.devdb_mirror.dv2_skill_mcq`) \n",
    "GROUP by 1\"\"\" %(\"(\" + devs + \")\")  \n",
    "\n",
    "ml_mcq = GBQ_data(ml_mcq_query)\n",
    "print(f\" ml_mcq Data shape is {ml_mcq.shape} and unique developers are {ml_mcq['dev_id'].nunique()}\")\n",
    "ml_mcq_zero_passed = ml_mcq.loc[ml_mcq.passed_num_challenges ==0 , ]\n",
    "ml_mcq = ml_mcq.loc[ml_mcq.passed_num_challenges > 0 , ]\n",
    "ml_mcq['passed_challenge_ids_set'] = ml_mcq['passed_challenge_ids'].apply(lambda x : x.split(',',-1)).apply(lambda x : set(map(int,x)))\n",
    "ml_mcq['challenge_ids_att_set'] = ml_mcq['challenge_ids'].apply(lambda x : x.split(',',-1)).apply(lambda x : set(map(int,x)))\n",
    "\n",
    "ml_mcq['num_passed_stack'] = None\n",
    "ml_mcq['num_attempted_stack'] = None\n",
    "ml_mcq['num_passed_skill'] = None\n",
    "ml_mcq['num_attempted_skill'] = None\n",
    "\n",
    "ml_mcq['passed_skill_id'] = None\n",
    "ml_mcq['passed_skill_name'] = None\n",
    "ml_mcq['passed_stack_id'] = None\n",
    "ml_mcq['passed_stack_name'] = None\n",
    "\n",
    "\n",
    "for i in ml_mcq.index:\n",
    "    num_passed_stack = 0\n",
    "    num_attempted_stack = 0\n",
    "    num_passed_skill = 0\n",
    "    num_attempted_skill = 0\n",
    "\n",
    "    list_id = []\n",
    "    list_name = []\n",
    "    stack_id = []\n",
    "    stack_name = []\n",
    "\n",
    "    for k in stack.index:\n",
    "        if stack['mcq_id_set'][k].issubset(ml_mcq['passed_challenge_ids_set'][i]):\n",
    "            stack_id.append(stack['stack_id'][k])\n",
    "            stack_name.append(stack['stack_name'][k])\n",
    "            num_passed_stack = num_passed_stack+1\n",
    "        if stack['mcq_id_set'][k].issubset(ml_mcq['challenge_ids_att_set'][i]):\n",
    "            num_attempted_stack = num_attempted_stack+1 \n",
    "\n",
    "    #ml_mcq['num_passed_stack'][i] = num_passed_stack\n",
    "    ml_mcq.at[i, 'num_passed_stack'] = num_passed_stack\n",
    "    ml_mcq.at[i, 'num_attempted_stack'] = num_attempted_stack\n",
    "    ml_mcq.at[i, 'passed_stack_id'] = stack_id\n",
    "    ml_mcq.at[i, 'passed_stack_name'] = stack_name\n",
    "\n",
    "    for m in skill.index:\n",
    "        if skill['mcq_id_set'][m].issubset(ml_mcq['passed_challenge_ids_set'][i]):\n",
    "            num_passed_skill = num_passed_skill+1\n",
    "            list_id.append(skill['skill_id'][m])\n",
    "            list_name.append(skill['skill_challenge_name'][m])\n",
    "        if skill['mcq_id_set'][m].issubset(ml_mcq['challenge_ids_att_set'][i]):\n",
    "            num_attempted_skill = num_attempted_skill+1 \n",
    "\n",
    "    #ml_mcq['num_passed_skill'][i] = num_passed_skill\n",
    "    ml_mcq.at[i, 'num_passed_skill'] = num_passed_skill\n",
    "    ml_mcq.at[i, 'num_attempted_skill'] = num_attempted_skill\n",
    "    ml_mcq.at[i, 'passed_skill_id'] = list_id\n",
    "    ml_mcq.at[i, 'passed_skill_name'] = list_name\n",
    "#print(f\"ml_mcq shape {ml_mcq.shape}\")\n",
    "vetted_stack_skill = pd.concat([ml_mcq, ml_mcq_zero_passed])\n",
    "\n",
    "df_phase2_cols = ['dev_id', 'vetting_status', 'phase2_entry_date', 'phase2_entry_source','count_jobs_suggested', 'count_jobs_packets_sent', 'count_jobs_selected_for_interview','paying_cust','count_paying_cust', 'count_trials', 'count_engagements']\n",
    "acc_score_cols = ['dev_id', 'acc_score', 'lci_score', 'acc_lci_score']\n",
    "vetted_stack_skill_cols = ['dev_id', 'num_challenges', 'passed_num_challenges','total_problems','attempted_problems','num_correct','mean_dev_percentile', 'num_passed_stack', 'passed_stack_id', 'passed_stack_name','num_passed_skill','passed_skill_id', 'passed_skill_name', 'passed_challenge_ids_set','challenge_ids_att_set']\n",
    "dev_detail_data_p1_cols = ['dev_id', 'signup_date', 'years_of_experience', 'words_in_resume','resume_upload_date', 'Region', 'source_attribution_type', 'channel', 'english_communication','full_name', 'email', 'hourly_rate']\n",
    "dev_detail_cols = ['dev_id', 'years_of_experience', 'characters_in_reume','resume_upload_date', 'region', 'country', 'verbal_communication', 'hourly_rate']\n",
    "p1_data_cols = ['dev_id', 'full_name', 'email' , 'signup_date','source_attribution_type', 'channel', 'user_os', 'user_os_type','quiz_answer', 'resume_flag', 'english_communication']\n",
    "dev_avaiability_cols = ['dev_id', 'latest_availability', 'updated_by', 'last_update_availability','notice_period']\n",
    "seniority_score_cols = ['dev_id', 'seniority_score']\n",
    "NTE_call_cols = ['dev_id', 'NTE_status']\n",
    "self_dec_skills_cols = ['dev_id', 'num_skill', 'dev_skill_id', 'dev_skill_name']\n",
    "\n",
    "\n",
    "global_data = pd.DataFrame()\n",
    "global_data = df_phase2[df_phase2_cols].merge(acc_lci[acc_score_cols], how='left', on='dev_id')\n",
    "global_data = global_data.merge(sns, how='left', on='dev_id')\n",
    "global_data = global_data.merge(developer_detail[dev_detail_cols], how='left', on='dev_id')\n",
    "global_data = global_data.merge(phase1_data[p1_data_cols], how='left', on='dev_id')\n",
    "global_data = global_data.merge(dev_availability, how='left', on='dev_id')\n",
    "global_data = global_data.merge(vetted_stack_skill[vetted_stack_skill_cols], how='left', on='dev_id')\n",
    "global_data = global_data.merge(nts, how='left', on='dev_id')\n",
    "global_data = global_data.merge(self_dec_skills[self_dec_skills_cols], how='left', on='dev_id')\n",
    "print(f\" Global Data shape is {global_data.shape} and unique developers are {global_data['dev_id'].nunique()}\")\n",
    "\n",
    "data_skill = global_data.loc[global_data['num_passed_skill']>0,].copy()\n",
    "try:\n",
    "    data_skill['top_skill_demand'] = np.select(\n",
    "        [\n",
    "            data_skill['passed_skill_name'].apply(lambda x:True if 'React' in x else False),\n",
    "            data_skill['passed_skill_name'].apply(lambda x:True if 'NodeJS' in x else False),\n",
    "            data_skill['passed_skill_name'].apply(lambda x:True if 'Python' in x else False), \n",
    "            data_skill['passed_skill_name'].apply(lambda x:True if 'JavaScript' in x else False)\n",
    "        ], \n",
    "        [\n",
    "            'React', \n",
    "            'NodeJS',\n",
    "            'Python',\n",
    "            'JavaScript'\n",
    "        ], \n",
    "        default='Other'\n",
    "    )\n",
    "\n",
    "    data_skill['top_skill_supply'] = np.select(\n",
    "        [\n",
    "            data_skill['passed_skill_name'].apply(lambda x:True if 'SQL' in x else False),\n",
    "            data_skill['passed_skill_name'].apply(lambda x:True if 'Git' in x else False),\n",
    "            data_skill['passed_skill_name'].apply(lambda x:True if 'Java' in x else False), \n",
    "            data_skill['passed_skill_name'].apply(lambda x:True if 'NodeJS' in x else False)\n",
    "        ], \n",
    "        [\n",
    "            'SQL', \n",
    "            'Git',\n",
    "            'Java',\n",
    "            'NodeJS'\n",
    "        ], \n",
    "        default='Other'\n",
    "    )\n",
    "except:\n",
    "    data_skill = pd.DataFrame(columns = ['dev_id','top_skill_supply','top_skill_demand'])\n",
    "\n",
    "data_stack = global_data.loc[global_data['num_passed_stack']>0,].copy()\n",
    "try:\n",
    "    data_stack['top_stack_supply'] = np.select(\n",
    "        [\n",
    "            data_stack['passed_stack_name'].apply(lambda x:True if 'React Native' in x else False),\n",
    "            data_stack['passed_stack_name'].apply(lambda x:True if 'Python (Flask/Vue/Angular)' in x else False),\n",
    "            data_stack['passed_stack_name'].apply(lambda x:True if 'React + Backend' in x else False), \n",
    "            data_stack['passed_stack_name'].apply(lambda x:True if 'Android (Kotlin)' in x else False)\n",
    "        ], \n",
    "        [\n",
    "            'React Native', \n",
    "            'Python (Flask/Vue/Angular)/Backend',\n",
    "            'React + Backend/Backend',\n",
    "            'Android (Kotlin)'\n",
    "        ], \n",
    "        default='Other'\n",
    "    )\n",
    "except:\n",
    "    data_stack = pd.DataFrame(columns = ['dev_id','top_stack_supply'])\n",
    "\n",
    "global_data = global_data.merge(data_skill[['dev_id','top_skill_supply','top_skill_demand']], how='left', on='dev_id')\n",
    "global_data = global_data.merge(data_stack[['dev_id','top_stack_supply']], how='left', on='dev_id')\n",
    "global_data.loc[global_data['passed_num_challenges']==0, 'num_passed_stack'] = 0\n",
    "global_data.loc[global_data['passed_num_challenges']==0, 'num_passed_skill'] = 0\n",
    "global_data.loc[global_data['passed_num_challenges']==0, 'top_skill_supply'] = 'No_skill_passed'\n",
    "global_data.loc[global_data['passed_num_challenges']==0, 'top_skill_demand'] = 'No_skill_passed'\n",
    "global_data.loc[global_data['passed_num_challenges']==0, 'top_stack_supply'] = 'No_stack_passed'\n",
    "global_data.loc[global_data['num_passed_stack']==0, 'top_stack_supply'] = 'No_stack_passed'\n",
    "global_data.loc[global_data['num_passed_skill']==0, 'top_skill_supply'] = 'No_skill_passed'\n",
    "global_data.loc[global_data['num_passed_skill']==0, 'top_skill_demand'] = 'No_skill_passed'\n",
    "global_data.loc[:,'correct_per_challenge'] = global_data.loc[:,'passed_num_challenges']/global_data.loc[:,'num_challenges']\n",
    "global_data.loc[:,'correct_per_questions'] =  global_data.loc[:,'num_correct']/global_data.loc[:,'total_problems']\n",
    "global_data['NTE_status'] = global_data['NTE_status'].fillna(0)\n",
    "print(f\" Global Data shape is {global_data.shape} and unique developers are {global_data['dev_id'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa8b3ae",
   "metadata": {},
   "source": [
    "## Store and version raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4807876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global Data of shape (136, 59) for new devs stored in a csv successfully\n"
     ]
    }
   ],
   "source": [
    "if global_data['dev_id'].duplicated().any():\n",
    "    print('Global Data for prediction has duplicated dev_id')\n",
    "else:\n",
    "    print(f'Global Data of shape {global_data.shape} for new devs stored in a csv successfully')\n",
    "    now = dt.datetime.now()\n",
    "    current_time = now.strftime(\"%d-%m-%y\") # %H:%M:%S\")\n",
    "    global_data.to_csv('../data/raw/' + '1.1-um-data-prep-predict-' + current_time+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae00e49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
