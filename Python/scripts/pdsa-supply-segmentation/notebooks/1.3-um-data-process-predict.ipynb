{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c879125",
   "metadata": {},
   "source": [
    "# Import data from csv and store in local after preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4242225",
   "metadata": {},
   "source": [
    "## Imports and global declarations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70f7f096",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 freeze > \"../requirements.txt\"\n",
    "#!pip3 install -r \"../requirements.txt\"  # giving some error\n",
    "\n",
    "from google.cloud import bigquery\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas_gbq\n",
    "import copy\n",
    "import copy\n",
    "import pickle\n",
    "import glob\n",
    "import re\n",
    "import datetime as dt\n",
    "from datetime import timezone\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44b8e77",
   "metadata": {},
   "source": [
    "## Load raw data from csv 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55eb7b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading prediction csv file from ../data/raw/1.1-um-data-prep-predict-09-08-22.csv\n"
     ]
    }
   ],
   "source": [
    "# . is any character except new line, he.{2} all should match where we have 2 characters after he\n",
    "# .*he mean any number of character before he\n",
    "a_predict = [re.search(r'\\d{2}-\\d{2}-\\d{2}', x).group(0) for x in glob.glob(\"../data/raw/1.1*\")]\n",
    "b_predict = sorted([dt.datetime.strptime(x,\"%d-%m-%y\") for x in a_predict])\n",
    "file_path = [val for val in glob.glob(\"../data/raw/1.1*\") if re.match('.*' + b_predict[-1].strftime('%d-%m-%y'),val)][0]\n",
    "print(f\"Loading prediction csv file from {file_path}\")\n",
    "predict_data = pd.read_csv(file_path, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bc15919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading All data csv file from ../data/raw/1.0-um-data-prep-all-04-08-22.csv\n"
     ]
    }
   ],
   "source": [
    "# . is any character except new line, he.{2} all should match where we have 2 characters after he\n",
    "# .*he mean any number of character before he\n",
    "a = [re.search(r'\\d{2}-\\d{2}-\\d{2}', x).group(0) for x in glob.glob(\"../data/raw/1.0*\")]\n",
    "b = sorted([dt.datetime.strptime(x,\"%d-%m-%y\") for x in a])\n",
    "raw_data_file_path = [val for val in glob.glob(\"../data/raw/1.0*\") if re.match('.*' + b[-1].strftime('%d-%m-%y'),val)][0]\n",
    "print(f\"Loading All data csv file from {raw_data_file_path}\")\n",
    "global_data = pd.read_csv(raw_data_file_path, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c3fe9b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking if we already have a cluster for a dev : 0\n"
     ]
    }
   ],
   "source": [
    "overalapping_devs = len(set(predict_data.dev_id.values).intersection(set(global_data.dev_id.values)))\n",
    "print(f\"Checking if we already have a cluster for a dev : {overalapping_devs}\") # Check\n",
    "if overalapping_devs==0:\n",
    "    predict_data.to_csv(raw_data_file_path, mode='a', header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f2560b",
   "metadata": {},
   "source": [
    "## Preprocessing, numerical coding , normalization\n",
    "- For this step, combining new dev data with old one (for which we already have cluster) and then do numerical coding and normalization at the end performing knn imputation for new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27844079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50805, 19) (50805, 1) (50805, 1)\n",
      "(136, 21)\n"
     ]
    }
   ],
   "source": [
    "data = pd.concat([global_data, predict_data])\n",
    "\n",
    "predictors = ['acc_lci_score', 'seniority_score', 'num_challenges', 'passed_num_challenges','total_problems','attempted_problems','num_correct','mean_dev_percentile','num_passed_stack', 'num_passed_skill', 'characters_in_reume','years_of_experience','top_skill_supply','top_skill_demand', 'top_stack_supply', 'correct_per_challenge', 'correct_per_questions', 'english_communication','quiz_answer']\n",
    "target     = ['paying_cust'] \n",
    "dev_id     = ['dev_id']\n",
    "\n",
    "\n",
    "ml_data_v2 = data[predictors+target+dev_id]\n",
    "num_cols   = [col for col in ml_data_v2.columns if ml_data_v2[col].dtype!='object']\n",
    "obj_cols   = [col for col in ml_data_v2.columns if ml_data_v2[col].dtype=='object']\n",
    "\n",
    "X      = ml_data_v2[predictors].copy()\n",
    "Y      = ml_data_v2[target]\n",
    "dev_id = ml_data_v2[dev_id]\n",
    "\n",
    "for col in (obj_cols):\n",
    "    X[col] = X[col].astype('category')\n",
    "    X[col] = X[col].cat.codes\n",
    "\n",
    "print(X.shape, Y.shape, dev_id.shape)\n",
    "\n",
    "scaler = StandardScaler().fit(X)\n",
    "rescaledX = scaler.transform(X)\n",
    "rescaledX = pd.DataFrame(rescaledX)\n",
    "rescaledX.columns = predictors\n",
    "\n",
    "\n",
    "temp_data = pd.concat([dev_id.reset_index(drop=True),Y.reset_index(drop=True), rescaledX],axis=1)\n",
    "norm_predict_data = temp_data.loc[temp_data['dev_id'].isin(list(predict_data.dev_id.values)),]\n",
    "print(norm_predict_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea006cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6dff9858",
   "metadata": {},
   "source": [
    "## Loading imputer model for imputation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e4d2451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../models/1.2-knnmputer-model-01-08-22.sav\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import re\n",
    "import datetime as dt\n",
    "a = [re.search(r'\\d{2}-\\d{2}-\\d{2}', x).group(0) for x in glob.glob(\"../models/1.2-knnmputer-model*\")]\n",
    "b = sorted([dt.datetime.strptime(x,\"%d-%m-%y\") for x in a])\n",
    "knnimpu_path=[val for val in glob.glob(\"../models/1.2-knnmputer-model*\") if re.match('.*' + b[-1].strftime('%d-%m-%y'),val)][0]\n",
    "print(knnimpu_path)\n",
    "loaded_model = pickle.load(open(knnimpu_path, 'rb'))\n",
    "X_final = pd.DataFrame(loaded_model.transform(norm_predict_data[predictors].to_numpy()))\n",
    "X_final.columns = predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa8b3ae",
   "metadata": {},
   "source": [
    "## Store and version process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b5819c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data for predicted devs stored in a csv with shape (562, 21)\n"
     ]
    }
   ],
   "source": [
    "data_dump = pd.concat([norm_predict_data[['dev_id', 'paying_cust']].reset_index(drop=True), X_final], axis=1)\n",
    "\n",
    "if data_dump['dev_id'].duplicated().any():\n",
    "    print('Processed Data Predicted has duplicated dev_id')\n",
    "else:\n",
    "    print(f\"Processed data for predicted devs stored in a csv with shape {data_dump.shape}\")\n",
    "    now = dt.datetime.now()\n",
    "    current_time = now.strftime(\"%d-%m-%y\") # %H:%M:%S\")\n",
    "    data_dump.to_csv('../data/processed/' + '1.3-um-data-process-predict-' + current_time+'.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
